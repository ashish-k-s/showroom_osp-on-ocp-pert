= Configure the Dataplane Network

Using a preconfigured yaml file(*files/osp-ng-dataplane-netconfig.yaml*) we will configure the topology for each data plane network.

If needed cd to files:

[source,bash]
----
cd ~/labrepo/content/files
----

Apply the *network confguration*:

[source,bash]
----
oc apply -f osp-ng-dataplane-netconfig.yaml
----

== Create VM for Dataplane

Log out from the bastion so that we go back to the hypervisor machine:

[source,bash]
----
logout
[root@hypervisor ~]#
----

Create the *RHEL compute* on lab-user(*hypervisor*) server:

[source,bash]
----
sudo -i
cd /var/lib/libvirt/images
cp rhel-9.3-x86_64-kvm.qcow2 rhel9-guest.qcow2
qemu-img info rhel9-guest.qcow2
qemu-img resize rhel9-guest.qcow2 +90G
chown -R qemu:qemu rhel9-*.qcow2
virt-customize -a rhel9-guest.qcow2 --run-command 'growpart /dev/sda 4'
virt-customize -a rhel9-guest.qcow2 --run-command 'xfs_growfs /'
virt-customize -a rhel9-guest.qcow2 --root-password password:redhat
virt-customize -a rhel9-guest.qcow2 --run-command 'systemctl disable cloud-init'
virt-customize -a /var/lib/libvirt/images/rhel9-guest.qcow2 --ssh-inject root:file:/root/.ssh/id_rsa.pub
virt-customize -a /var/lib/libvirt/images/rhel9-guest.qcow2 --selinux-relabel
qemu-img create -f qcow2 -F qcow2 -b /var/lib/libvirt/images/rhel9-guest.qcow2 /var/lib/libvirt/images/osp-compute-0.qcow2
virt-install --virt-type kvm --ram 16384 --vcpus 4 --cpu=host-passthrough --os-variant rhel8.4 --disk path=/var/lib/libvirt/images/osp-compute-0.qcow2,device=disk,bus=virtio,format=qcow2 --network network:ocp4-provisioning --network network:ocp4-net --boot hd,network --noautoconsole --vnc --name osp-compute0 --noreboot
virsh start osp-compute0
----

=== Login to the Compute and verify

Verify IP from 192.168.123.0/24

[source,bash]
----
watch virsh domifaddr osp-compute0 --source agent
----
Output:
[source,bash]
----
Every 2.0s: virsh domifaddr osp-compute0 --source agent                                                                                                 hypervisor: Wed Apr 17 07:03:13 2024

 Name       MAC address          Protocol     Address
-------------------------------------------------------------------------------
 lo         00:00:00:00:00:00    ipv4         127.0.0.1/8
 -          -                    ipv6         ::1/128
 eth0       52:54:00:c0:0a:26    ipv4         172.22.0.202/24
 -          -                    ipv6         fe80::16:d083:92f4:f201/64
 eth1       52:54:00:e5:ce:09    ipv4         192.168.123.61/24
 -          -                    ipv6         fe80::bfc0:e5db:a655:729f/64
----

(control + C to continue)

[source,bash]
----
virsh domifaddr osp-compute0 --source agent
----
ssh to the IP assigned

[source,bash]
----
ssh root@192.168.123.61
----

==== Configure ethernet devices

[source,bash]
----
nmcli co delete 'Wired connection 1'
nmcli con add con-name "static-eth0" ifname eth0 type ethernet ip4 172.22.0.100/24 ipv4.dns "172.22.0.89"
nmcli con up "static-eth0"
nmcli co delete 'Wired connection 2'
nmcli con add con-name "static-eth1" ifname eth1 type ethernet ip4 192.168.123.61/24 ipv4.dns "192.168.123.100" ipv4.gateway "192.168.123.1"
nmcli con up "static-eth1"
----

And log off VM

[source,bash]
----
logout
----

==== Log into the compute server, set hostname, and subscribe it with a validated account

[source,bash]
----
ssh root@172.22.0.100
sudo hostnamectl set-hostname edpm-compute-0.aio.example.com
----

==== Configure for the RHEL 9.3 Repos

[source,bash]
----
sudo subscription-manager register --org="Red_Hat_RHDP_Labs" --activationkey="demosat-smt-b1374-1711111157"
sudo subscription-manager repos --disable=*
subscription-manager repos --enable=rhceph-6-tools-for-rhel-9-x86_64-rpms --enable=rhel-9-for-x86_64-baseos-rpms --enable=rhel-9-for-x86_64-appstream-rpms --enable=rhel-9-for-x86_64-highavailability-rpms --enable=openstack-17.1-for-rhel-9-x86_64-rpms --enable=fast-datapath-for-rhel-9-x86_64-rpms
sudo subscription-manager release --set=9.3
----

==== Install podman on the compute and login to registries

[source,bash]
----
sudo dnf install -y podman
----

Log off

[source,bash]
----
logout
----

=== Snapshot the Compute

[source,bash]
----
virsh snapshot-create-as osp-compute0 preprovisioned
----

=== Set SSH key

[source,bash]
----
scp /root/.ssh/id_rsa root@192.168.123.100:/root/.ssh/id_rsa_compute
scp /root/.ssh/id_rsa.pub root@192.168.123.100:/root/.ssh/id_rsa_compute.pub
----

== Create a secret for the dataplane

Back on the *bastion* server (Remember that bastion password is redhat):

[source,bash]
----
[lab-user@hypervisor ~]$ ssh root@192.168.123.100
----

[source,bash]
----
cd ~/labrepo/content/files
----

[source,bash]
----
oc create secret generic dataplane-ansible-ssh-private-key-secret --save-config --dry-run=client --from-file=authorized_keys=/root/.ssh/id_rsa_compute.pub --from-file=ssh-privatekey=/root/.ssh/id_rsa_compute --from-file=ssh-publickey=/root/.ssh/id_rsa_compute.pub -n openstack -o yaml | oc apply -f-
ssh-keygen -f ./id -t ecdsa-sha2-nistp521 -N ''
oc create secret generic nova-migration-ssh-key --from-file=ssh-privatekey=id --from-file=ssh-publickey=id.pub -n openstack -o yaml | oc apply -f-
----

Deploy the Dataplane

[source,bash]
----
oc apply -f osp-ng-dataplane-node-set-deploy.yaml
oc apply -f osp-ng-dataplane-deployment.yaml
----

You can view the Ansible logs while the deployment executes:

[source,bash]
----
oc logs -l app=openstackansibleee -f --max-log-requests 10
----

Verify that the data plane is deployed:
[source,bash]
----
$ oc get openstackdataplanedeployment
NAME             	STATUS   MESSAGE
openstack-edpm-ipam   True     Setup Complete


$ oc get openstackdataplanenodeset
NAME             	STATUS   MESSAGE
openstack-edpm-ipam   True     NodeSet Ready
----